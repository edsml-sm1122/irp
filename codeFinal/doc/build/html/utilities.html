<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>utilities module &#8212; IRP ... documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=039e1c02" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=f85b753c"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="data_functions module" href="data_functions.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-utilities">
<span id="utilities-module"></span><h1>utilities module<a class="headerlink" href="#module-utilities" title="Permalink to this heading">¶</a></h1>
<p>utilities.ipynb</p>
<p>Automatically generated by Colaboratory.</p>
<dl class="simple">
<dt>Original file is located at</dt><dd><p><a class="reference external" href="https://colab.research.google.com/drive/1cOa-8iNEWs3XNVdK30v_Kjma5sMHg5a9">https://colab.research.google.com/drive/1cOa-8iNEWs3XNVdK30v_Kjma5sMHg5a9</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilities.LSTM">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">LSTM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Long Short-Term Memory (LSTM) network implemented using PyTorch’s nn.Module.</p>
<p>This class encapsulates a multi-layer LSTM network with an optional final linear layer to map the hidden state
to the output space.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The dimensionality of the input tensor.</p></li>
<li><p><strong>hidden_size</strong> – The dimensionality of the hidden and cell states.</p></li>
<li><p><strong>num_layers</strong> – The number of LSTM layers in the network.</p></li>
<li><p><strong>bias</strong> – Boolean flag to include bias terms in LSTM cells. Default is False.</p></li>
<li><p><strong>output_size</strong> – The dimensionality of the output tensor.</p></li>
<li><p><strong>device</strong> – Computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
<li><p><strong>rnn_cell_list</strong> – List of LSTM cells, one for each layer.</p></li>
<li><p><strong>h2o</strong> – Optional linear layer mapping from the last layer’s hidden state to the output size.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="utilities.LSTM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation for the LSTM network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>torch.Tensor</em>) – Input tensor for the entire sequence, shape (batch_size, sequence_length, input_size).</p></li>
<li><p><strong>h0</strong> (<em>torch.Tensor</em>) – Initial hidden state for each layer, shape (num_layers, batch_size, hidden_size).</p></li>
<li><p><strong>c0</strong> (<em>torch.Tensor</em>) – Initial cell state for each layer, shape (num_layers, batch_size, hidden_size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor for the entire sequence, shape (batch_size, sequence_length, output_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilities.LSTM.init_hidden">
<span class="sig-name descname"><span class="pre">init_hidden</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTM.init_hidden" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the hidden and cell states for the LSTM network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size for the initial states.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Initialized hidden and cell states.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple(torch.Tensor, torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilities.LSTMCell">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">LSTMCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTMCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Long Short-Term Memory (LSTM) cell implemented using PyTorch’s nn.Module.</p>
<p>This class encapsulates the key operations for an LSTM unit, including input, forget, and output gates along
with candidate state updates.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The dimensionality of the input tensor.</p></li>
<li><p><strong>hidden_size</strong> – The dimensionality of the hidden and cell states.</p></li>
<li><p><strong>bias</strong> – Boolean flag to include bias terms in linear transformations. Default is True.</p></li>
<li><p><strong>i2h</strong> – Linear layer mapping input to hidden state with 4 times the hidden size to accommodate all gates.</p></li>
<li><p><strong>h2h</strong> – Linear layer mapping previous hidden state to current hidden state with 4 times the hidden size to accommodate all gates.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="utilities.LSTMCell.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTMCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass for the LSTM cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>torch.Tensor</em>) – Input tensor for the current time step.</p></li>
<li><p><strong>h</strong> (<em>torch.Tensor</em>) – Hidden state tensor for the previous time step.</p></li>
<li><p><strong>c</strong> (<em>torch.Tensor</em>) – Cell state tensor for the previous time step.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the next hidden state and the next cell state.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple(torch.Tensor, torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilities.LSTMCell.reset_parameters">
<span class="sig-name descname"><span class="pre">reset_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTMCell.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the weights of the LSTM cell with a uniform distribution.</p>
<p>Initialization is based on the size of the hidden state.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilities.LSTM_GEN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">LSTM_GEN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTM_GEN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Wrapper class for the LSTM network, designed for specific generative tasks.</p>
<p>This class serves as an interface for the LSTM model. It takes care of initializing the hidden
and cell states, and provides a forward method to propagate the input through the LSTM network.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The dimensionality of the input tensor.</p></li>
<li><p><strong>hidden_size</strong> – The dimensionality of the hidden and cell states.</p></li>
<li><p><strong>num_layers</strong> – The number of LSTM layers in the network.</p></li>
<li><p><strong>output_size</strong> – The dimensionality of the output tensor.</p></li>
<li><p><strong>device</strong> – Computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
<li><p><strong>lstm</strong> – Instance of the LSTM class encapsulating the LSTM network.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="utilities.LSTM_GEN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.LSTM_GEN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation for the LSTM_GEN network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Input tensor for the entire sequence, shape (batch_size, sequence_length, input_size).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor for the entire sequence, shape (batch_size, sequence_length, output_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilities.MLPDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">MLPDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.MLPDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDataset</span></code></p>
<p>Custom dataset class for handling features and targets for a Multilayer Perceptron (MLP) model.</p>
<p>Inherits from the <cite>TensorDataset</cite> class in PyTorch’s utility data module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature</strong> (<em>numpy.ndarray</em>) – The feature data, expected to be a numpy array.</p></li>
<li><p><strong>target</strong> (<em>numpy.ndarray</em>) – The target data, expected to be a numpy array.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.calculate_metrics">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">calculate_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.calculate_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate various statistical metrics between two arrays, including MAE and MAPE.</p>
<p>Parameters:
- y_true : array-like, true target values
- y_pred : array-like, predicted target values</p>
<p>Returns:
- metrics : Dictionary containing Bias, RMSE, Scatter Index, Correlation Coefficient, Coefficient of Efficiency, Index of Agreement, MAE, and MAPE</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.convert_deg_to_sin_cos">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">convert_deg_to_sin_cos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arr</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.convert_deg_to_sin_cos" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts specific columns in a 3D numpy array from degrees to their sine and cosine values.</p>
<p>The function operates on the first and fifth columns of the last axis. The original values in these columns
are converted from degrees to radians, and then to their sine and cosine values. These newly computed values
replace the original first and fifth columns.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>arr</strong> (<em>numpy.ndarray</em>) – Input 3D numpy array. The shape is assumed to be (m, n, p) where m, n, and p are integers.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new 3D numpy array where the first and fifth columns in the last axis are replaced with their sine and cosine values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.count_trainable_parameters">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">count_trainable_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.count_trainable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the total number of trainable parameters in a PyTorch model.</p>
<p>This function iterates over all parameters in a given PyTorch model and sums up the number of trainable
parameters, i.e., those that require gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>torch.nn.Module</em>) – The PyTorch model for which the number of trainable parameters is to be counted.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The total number of trainable parameters in the model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.generate_random_numbers">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">generate_random_numbers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.generate_random_numbers" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a list of unique random numbers within a specified range [a, b].</p>
<p>This function uses Python’s <cite>random.sample()</cite> to generate a list of unique random integers within the range [a, b].
The function validates that the length of the list <cite>x</cite> is within the permissible range before generating the numbers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>int</em>) – The number of unique random integers to generate.</p></li>
<li><p><strong>a</strong> (<em>int</em>) – The start of the range within which to generate random numbers.</p></li>
<li><p><strong>b</strong> (<em>int</em>) – The end of the range within which to generate random numbers.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of x unique random integers within the range [a, b]. Returns an empty list if x &gt; (b - a + 1).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilities.lstmDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">lstmDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.lstmDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDataset</span></code></p>
<p>Custom dataset class for handling sequence data for LSTM models.</p>
<p>Inherits from the <cite>TensorDataset</cite> class in PyTorch’s utility data module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature</strong> (<em>numpy.ndarray</em>) – The feature data, expected to be a numpy array.</p></li>
<li><p><strong>target</strong> (<em>numpy.ndarray</em>) – The target data, expected to be a numpy array.</p></li>
<li><p><strong>sequence_length</strong> (<em>int</em>) – The length of each sequence.</p></li>
<li><p><strong>intervel</strong> (<em>int</em>) – The interval between each track in the sequence data. Default is 97.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.mlptrain">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">mlptrain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.mlptrain" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains a given MLP (Multilayer Perceptron) model on the provided data using the specified loss criterion and optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The MLP model to be trained.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimization algorithm to be used for model training.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.Module</em>) – The loss function to be used for model training.</p></li>
<li><p><strong>data_loader</strong> (<em>torch.utils.data.DataLoader</em>) – DataLoader object containing the training dataset.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average training loss computed over the entire dataset.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.mlpvalidate">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">mlpvalidate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.mlpvalidate" title="Permalink to this definition">¶</a></dt>
<dd><p>Validates a given MLP (Multilayer Perceptron) model on the provided data using the specified loss criterion.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The MLP model to be validated.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.Module</em>) – The loss function to be used for model validation.</p></li>
<li><p><strong>data_loader</strong> (<em>torch.utils.data.DataLoader</em>) – DataLoader object containing the validation dataset.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average validation loss computed over the entire dataset.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.normalize">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arr</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalizes a given 2D numpy array along first axis.</p>
<p>The normalization is done by subtracting the mean and dividing by the standard deviation of each column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>arr</strong> (<em>numpy.ndarray</em>) – Input 2D numpy array. The shape is assumed to be (m, n) where m and n are integers.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing the computed mean, standard deviation, and the normalized array.
- mean: 1D numpy array containing the mean of each column.
- std: 1D numpy array containing the standard deviation of each column.
- arr_normalized: 2D numpy array containing the normalized values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple(numpy.ndarray, numpy.ndarray, numpy.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilities.simpleFFN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">simpleFFN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.simpleFFN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A simple Feed-Forward Neural Network (FFN) class implemented using PyTorch’s nn.Module.</p>
<p>The network comprises three hidden layers and one output layer, with LeakyReLU activation functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_1</strong> – First hidden layer with input size 1240 and output size 50.</p></li>
<li><p><strong>hidden_2</strong> – Second hidden layer with input size 50 and output size 50.</p></li>
<li><p><strong>hidden_3</strong> – Third hidden layer with input size 50 and output size 50.</p></li>
<li><p><strong>output</strong> – Output layer with input size 50 and output size 145.</p></li>
<li><p><strong>activation</strong> – LeakyReLU activation function used between layers.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="utilities.simpleFFN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.simpleFFN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the forward propagation logic for the neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – Input tensor with shape (batch_size, 1240)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor with shape (batch_size, 145)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.train_lstm_gen">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">train_lstm_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.train_lstm_gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains an LSTM-based generative model on a given dataset.</p>
<p>This function performs one epoch of training, iterating over the provided DataLoader.
It computes the loss, performs backpropagation, and updates the model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The PyTorch model to be trained.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – The optimizer for updating model parameters.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.Module</em>) – The loss function.</p></li>
<li><p><strong>dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – DataLoader for the training data.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Average training loss for the epoch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilities.val_lstm_gen">
<span class="sig-prename descclassname"><span class="pre">utilities.</span></span><span class="sig-name descname"><span class="pre">val_lstm_gen</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilities.val_lstm_gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Validates an LSTM-based generative model on a given dataset.</p>
<p>This function performs one epoch of validation, iterating over the provided DataLoader.
It computes the loss but does not update the model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The PyTorch model to be validated.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.Module</em>) – The loss function.</p></li>
<li><p><strong>dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – DataLoader for the validation data.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Computational device (‘cpu’ or ‘cuda’) where tensors should be moved to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Average validation loss for the epoch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">IRP</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">codeFinal</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="data_functions.html">data_functions module</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">utilities module</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="modules.html">codeFinal</a><ul>
      <li>Previous: <a href="data_functions.html" title="previous chapter">data_functions module</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Sitong Mu.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/utilities.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>