# -*- coding: utf-8 -*-
# Name: Sitong Mu; Github username: edsml-sm1122
"""utilities.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cOa-8iNEWs3XNVdK30v_Kjma5sMHg5a9
"""

import numpy as np
import pandas as pd
import pickle
from pathlib import Path
import datetime, time
import matplotlib.pyplot as plt
from torch.utils.data import TensorDataset, DataLoader, Dataset
from tqdm import tqdm
from sklearn.metrics import mean_squared_error as mse
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedShuffleSplit
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchsummary import summary
import random
from sklearn.metrics import mean_squared_error, mean_absolute_error

# as in James et al., 2018 and Peach et al., 2023
def convert_deg_to_sin_cos(arr):
    """
    Converts specific columns in a 3D numpy array from degrees to their sine and cosine values.

    The function operates on the first and fifth columns of the last axis. The original values in these columns
    are converted from degrees to radians, and then to their sine and cosine values. These newly computed values
    replace the original first and fifth columns.

    :param arr: Input 3D numpy array. The shape is assumed to be (m, n, p) where m, n, and p are integers.
    :type arr: numpy.ndarray
    :return: A new 3D numpy array where the first and fifth columns in the last axis are replaced with their sine and cosine values.
    :rtype: numpy.ndarray
    """
        
    # Copy the first and fifth parameters, convert them from degrees to radians
    sin_first_param = np.sin(np.radians(arr[:,:,0])).reshape(arr.shape[0], arr.shape[1], 1)
    cos_first_param = np.cos(np.radians(arr[:,:,0])).reshape(arr.shape[0], arr.shape[1], 1)
    sin_fifth_param = np.sin(np.radians(arr[:,:,4])).reshape(arr.shape[0], arr.shape[1], 1)
    cos_fifth_param = np.cos(np.radians(arr[:,:,4])).reshape(arr.shape[0], arr.shape[1], 1)

    # Replace the first and fifth parameter with their sine and cosine
    arr_new = np.concatenate((sin_first_param, cos_first_param, arr[:,:,1:4], sin_fifth_param, cos_fifth_param, arr[:,:,5:]), axis=2)

    return arr_new


def normalize(arr):
    """
    Normalizes a given 2D numpy array along first axis.

    The normalization is done by subtracting the mean and dividing by the standard deviation of each column.

    :param arr: Input 2D numpy array. The shape is assumed to be (m, n) where m and n are integers.
    :type arr: numpy.ndarray
    :return: A tuple containing the computed mean, standard deviation, and the normalized array.
        - mean: 1D numpy array containing the mean of each column.
        - std: 1D numpy array containing the standard deviation of each column.
        - arr_normalized: 2D numpy array containing the normalized values.
    :rtype: tuple(numpy.ndarray, numpy.ndarray, numpy.ndarray)
    """

    # Compute mean and std dev
    mean = np.mean(arr, axis=0)
    std = np.std(arr, axis=0)

    # Subtract mean and divide by std dev
    arr_normalized = (arr - mean) / std

    return mean, std, arr_normalized

class MLPDataset(TensorDataset):
    """
    Custom dataset class for handling features and targets for a Multilayer Perceptron (MLP) model.
    
    Inherits from the `TensorDataset` class in PyTorch's utility data module.

    :param feature: The feature data, expected to be a numpy array.
    :type feature: numpy.ndarray
    :param target: The target data, expected to be a numpy array.
    :type target: numpy.ndarray
    """

    def __init__(self, feature, target):
      assert (len(feature)==len(target))
      self.feature = feature.astype('float32')
      self.target = target.astype('float32')

    def __getitem__(self, idx):
        """
        Retrieves the feature and target pair at the given index.

        :param idx: Index of the desired data point.
        :type idx: int
        :return: A tuple containing the feature and target numpy arrays at the specified index.
        :rtype: tuple(numpy.ndarray, numpy.ndarray)
        """
        return self.feature[idx], self.target[idx]

    def __len__(self):
        """
        Returns the total number of data points in the dataset.

        :return: The number of data points in the dataset.
        :rtype: int
        """
        return len(self.feature)


class lstmDataset(TensorDataset):
    """
    Custom dataset class for handling sequence data for LSTM models.

    Inherits from the `TensorDataset` class in PyTorch's utility data module.

    :param feature: The feature data, expected to be a numpy array.
    :type feature: numpy.ndarray
    :param target: The target data, expected to be a numpy array.
    :type target: numpy.ndarray
    :param sequence_length: The length of each sequence.
    :type sequence_length: int
    :param intervel: The interval between each track in the sequence data. Default is 97.
    :type intervel: int
    """

    def __init__(self, feature, target, sequence_length,intervel=97):
        assert (len(feature) == len(target))
        assert (len(feature)%intervel == 0)
        self.feature = feature.astype('float64')
        self.target = target.astype('float64')
        self.sequence_length = sequence_length
        self.intervel = intervel


    def __getitem__(self, idx):
        """
        Retrieves a sequence of feature-target pairs at the given index.

        :param idx: Index of the desired sequence.
        :type idx: int
        :return: A tuple containing the feature and target sequences at the specified index.
        :rtype: tuple(torch.Tensor, torch.Tensor)
        """

      # as the data consists of 100+ tracks, each of timesteps 97. To avoid using the end of last track to predict start of next track, set the ind as the formula below
        ind = ((idx) // (self.intervel-self.sequence_length+1))*(self.sequence_length-1) + idx
        sample_input = torch.tensor(self.feature[ind:ind+self.sequence_length])       # get a sample input sequence
        sample_output = torch.tensor(self.target[ind:ind+self.sequence_length])  # get a sample output sequence

        # return sample_input.type('torch.DoubleTensor'), sample_output.type('torch.DoubleTensor')
        return sample_input, sample_output

    def __len__(self):
        """
        Returns the total number of sequences in the dataset.

        :return: The number of sequences in the dataset.
        :rtype: int
        """

        return int(len(self.feature) - (len(self.feature)/self.intervel) * (self.sequence_length - 1) )


# model

class simpleFFN(nn.Module):
    """
    A simple Feed-Forward Neural Network (FFN) class implemented using PyTorch's nn.Module.
    
    The network comprises three hidden layers and one output layer, with LeakyReLU activation functions.

    :ivar hidden_1: First hidden layer with input size 1240 and output size 50.
    :ivar hidden_2: Second hidden layer with input size 50 and output size 50.
    :ivar hidden_3: Third hidden layer with input size 50 and output size 50.
    :ivar output: Output layer with input size 50 and output size 145.
    :ivar activation: LeakyReLU activation function used between layers.
    """
    def __init__(self):
        super(simpleFFN, self).__init__()
        self.hidden_1 = nn.Linear(1240, 50, bias=False) 
        self.hidden_2 = nn.Linear(50, 50, bias=False) 
        self.hidden_3 = nn.Linear(50,50)               
        self.output = nn.Linear(50, 145, bias=False)
        self.activation = nn.LeakyReLU()

    def forward(self, X):
        """
        Defines the forward propagation logic for the neural network.

        :param X: Input tensor with shape (batch_size, 1240)
        :type X: torch.Tensor
        :return: Output tensor with shape (batch_size, 145)
        :rtype: torch.Tensor
        """

        z1 = self.hidden_1(X)
        a1 = self.activation(z1)
        z2 = self.hidden_2(a1)
        a2 = self.activation(z2)
        z3 = self.hidden_3(a2)    
        a3 = self.activation(z3)  
        z4 = self.output(a3)      
        a4 = self.activation(z4)
        return a4                 

def mlptrain(model, optimizer, criterion, data_loader,device):
    """
    Trains a given MLP (Multilayer Perceptron) model on the provided data using the specified loss criterion and optimizer.

    :param model: The MLP model to be trained.
    :type model: torch.nn.Module
    :param optimizer: The optimization algorithm to be used for model training.
    :type optimizer: torch.optim.Optimizer
    :param criterion: The loss function to be used for model training.
    :type criterion: torch.nn.Module
    :param data_loader: DataLoader object containing the training dataset.
    :type data_loader: torch.utils.data.DataLoader
    :param device: The computational device ('cpu' or 'cuda') where tensors should be moved to.
    :type device: str
    :return: The average training loss computed over the entire dataset.
    :rtype: float
    """

    model.train()                         
    train_loss, train_accuracy = 0, 0    
    for X, y in data_loader:              
        X, y = X.to(device), y.to(device) 
        optimizer.zero_grad()            
        a2 = model(X)    
        loss = criterion(a2, y)          
        loss.backward()                   
        train_loss += loss*X.size(0)      
        optimizer.step()                  

    return train_loss/len(data_loader.dataset) 


def mlpvalidate(model, criterion, data_loader,device):
    """
    Validates a given MLP (Multilayer Perceptron) model on the provided data using the specified loss criterion.

    :param model: The MLP model to be validated.
    :type model: torch.nn.Module
    :param criterion: The loss function to be used for model validation.
    :type criterion: torch.nn.Module
    :param data_loader: DataLoader object containing the validation dataset.
    :type data_loader: torch.utils.data.DataLoader
    :param device: The computational device ('cpu' or 'cuda') where tensors should be moved to.
    :type device: str
    :return: The average validation loss computed over the entire dataset.
    :rtype: float
    """

    model.eval()                                  
    validation_loss, validation_accuracy = 0., 0.
    for X, y in data_loader:                     
        with torch.no_grad():                    
            X, y = X.to(device), y.to(device)    
            a2 = model(X)         
            loss = criterion(a2, y)               
            validation_loss += loss*X.size(0)     
    return validation_loss/len(data_loader.dataset) 


def generate_random_numbers(x, a, b):
    """
    Generates a list of unique random numbers within a specified range [a, b].

    This function uses Python's `random.sample()` to generate a list of unique random integers within the range [a, b].
    The function validates that the length of the list `x` is within the permissible range before generating the numbers.

    :param x: The number of unique random integers to generate.
    :type x: int
    :param a: The start of the range within which to generate random numbers.
    :type a: int
    :param b: The end of the range within which to generate random numbers.
    :type b: int
    :return: A list of x unique random integers within the range [a, b]. Returns an empty list if x > (b - a + 1).
    :rtype: list[int]
    """

    if x > (b - a + 1):
        print("Error: x should be less or equal to the total numbers in range a to b")
        return []
    else:
        return random.sample(range(a, b+1), x)




class LSTMCell(nn.Module):
    """
    Long Short-Term Memory (LSTM) cell implemented using PyTorch's nn.Module.

    This class encapsulates the key operations for an LSTM unit, including input, forget, and output gates along
    with candidate state updates.

    :ivar input_size: The dimensionality of the input tensor.
    :ivar hidden_size: The dimensionality of the hidden and cell states.
    :ivar bias: Boolean flag to include bias terms in linear transformations. Default is True.
    :ivar i2h: Linear layer mapping input to hidden state with 4 times the hidden size to accommodate all gates.
    :ivar h2h: Linear layer mapping previous hidden state to current hidden state with 4 times the hidden size to accommodate all gates.
    """

    def __init__(self, input_size, hidden_size, bias=True):
        super(LSTMCell, self).__init__()

        self.input_size = input_size
        self.hidden_size = hidden_size
        self.bias = bias

        self.i2h = nn.Linear(input_size, hidden_size * 4, bias=bias)       # create a linear layer to map from input to hidden space, *4 as he chunks to 4 gate in line 26
        self.h2h = nn.Linear(hidden_size, hidden_size * 4, bias=bias)      # create a linear layer to map from previous to current hidden space

        self.reset_parameters()                                            # initialise the parameters

    def reset_parameters(self):
        """
        Initializes the weights of the LSTM cell with a uniform distribution.

        Initialization is based on the size of the hidden state.
        """
        std = 1.0 / np.sqrt(self.hidden_size)

        for w in self.parameters():
            w.data.uniform_(-std, std)

    def forward(self, input, h, c):
        """
        Forward pass for the LSTM cell.

        :param input: Input tensor for the current time step.
        :type input: torch.Tensor
        :param h: Hidden state tensor for the previous time step.
        :type h: torch.Tensor
        :param c: Cell state tensor for the previous time step.
        :type c: torch.Tensor
        :return: A tuple containing the next hidden state and the next cell state.
        :rtype: tuple(torch.Tensor, torch.Tensor)
        """
  
        gates = self.i2h(input) + self.h2h(h)                              # apply the weights to both input and previous state

        input_gate, forget_gate, candidate_update, output_gate = gates.chunk(4, 1)  # separate the output into each of the LSTM operations

        # apply the corresponding activations
        i_t = torch.sigmoid(input_gate)
        f_t = torch.sigmoid(forget_gate)
        c_t = torch.tanh(candidate_update)
        o_t = torch.sigmoid(output_gate)

        c = f_t * c + i_t * c_t                                             # calculate the next cell state

        h = o_t * torch.tanh(c)                                             # calculate the next hidden state

        return h, c



class LSTM(nn.Module):
    """
    Long Short-Term Memory (LSTM) network implemented using PyTorch's nn.Module.
    
    This class encapsulates a multi-layer LSTM network with an optional final linear layer to map the hidden state 
    to the output space.

    :ivar input_size: The dimensionality of the input tensor.
    :ivar hidden_size: The dimensionality of the hidden and cell states.
    :ivar num_layers: The number of LSTM layers in the network.
    :ivar bias: Boolean flag to include bias terms in LSTM cells. Default is False.
    :ivar output_size: The dimensionality of the output tensor.
    :ivar device: Computational device ('cpu' or 'cuda') where tensors should be moved to.
    :ivar rnn_cell_list: List of LSTM cells, one for each layer.
    :ivar h2o: Optional linear layer mapping from the last layer's hidden state to the output size.
    """

    def __init__(self, input_size, output_size, hidden_size, num_layers, device, bias=False):
        super(LSTM, self).__init__()

        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.bias = bias
        self.output_size = output_size
        self.device = device
        self.rnn_cell_list = nn.ModuleList()                         


        for l in range(self.num_layers):
            self.rnn_cell_list.append(LSTMCell(self.input_size if l == 0 else self.hidden_size,
                                               self.hidden_size,
                                               self.bias))

        self.h2o = nn.Linear(self.hidden_size, self.output_size)  

    def init_hidden(self,  batch_size=1,device = 'cuda'):
        """
        Initializes the hidden and cell states for the LSTM network.

        :param batch_size: The batch size for the initial states.
        :type batch_size: int
        :param device: The computational device ('cpu' or 'cuda') where tensors should be moved to.
        :type device: str
        :return: Initialized hidden and cell states.
        :rtype: tuple(torch.Tensor, torch.Tensor)
        """
            
        # initialise the hidden state and cell state
        return (torch.zeros(self.num_layers, batch_size, self.hidden_size, requires_grad=False,dtype=torch.double).to(device),
                torch.zeros(self.num_layers, batch_size, self.hidden_size, requires_grad=False,dtype=torch.double).to(device))

    def forward(self, input, h0, c0):
        """
        Forward propagation for the LSTM network.

        :param input: Input tensor for the entire sequence, shape (batch_size, sequence_length, input_size).
        :type input: torch.Tensor
        :param h0: Initial hidden state for each layer, shape (num_layers, batch_size, hidden_size).
        :type h0: torch.Tensor
        :param c0: Initial cell state for each layer, shape (num_layers, batch_size, hidden_size).
        :type c0: torch.Tensor
        :return: Output tensor for the entire sequence, shape (batch_size, sequence_length, output_size).
        :rtype: torch.Tensor
        """

        outs = []

        hidden = []
        cell = []
        for layer in range(self.num_layers):
            hidden.append(h0[layer, :, :])
            cell.append(c0[layer, :, :])

        # iterate over all elements in the sequence
        for t in range(input.size(1)): # size 1 is windows length
            # iterate over each layer
            for layer in range(self.num_layers):
                # apply each layer
                if layer == 0:
                    hidden_l, cell_l = self.rnn_cell_list[layer](input[:, t, :], hidden[layer], cell[layer])
                else:
                    hidden_l, cell_l = self.rnn_cell_list[layer](hidden[layer-1], hidden[layer], cell[layer])

                # store the hidden and cell state of each layer
                hidden[layer] = hidden_l
                cell[layer] = cell_l   # useless

            outs.append(hidden_l)

        # output for each member in the sequence
        out = torch.stack([self.h2o(out) for out in outs], dim=1)

        return out




class LSTM_GEN(nn.Module):
    """
    Wrapper class for the LSTM network, designed for specific generative tasks.
    
    This class serves as an interface for the LSTM model. It takes care of initializing the hidden 
    and cell states, and provides a forward method to propagate the input through the LSTM network.

    :ivar input_size: The dimensionality of the input tensor.
    :ivar hidden_size: The dimensionality of the hidden and cell states.
    :ivar num_layers: The number of LSTM layers in the network.
    :ivar output_size: The dimensionality of the output tensor.
    :ivar device: Computational device ('cpu' or 'cuda') where tensors should be moved to.
    :ivar lstm: Instance of the LSTM class encapsulating the LSTM network.
    """

    def __init__(self, input_size, output_size, hidden_size, num_layers,device):
        super(LSTM_GEN, self).__init__()

        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.output_size = output_size
        self.lstm = LSTM(self.input_size,self.output_size, self.hidden_size, self.num_layers,device=device) # add out LSTM
        self.device = device

    def forward(self, x):
        """
        Forward propagation for the LSTM_GEN network.
        
        :param x: Input tensor for the entire sequence, shape (batch_size, sequence_length, input_size).
        :type x: torch.Tensor
        :return: Output tensor for the entire sequence, shape (batch_size, sequence_length, output_size).
        :rtype: torch.Tensor
        """
        batch_size = x.size(0)
        state_h, state_c = self.lstm.init_hidden(batch_size,device = x.device.type)    # initialise hidden state
        state_h.to(torch.double)

        output = self.lstm(x, state_h, state_c)          # apply the LSTM

        return output


def count_trainable_parameters(model):
    """
    Computes the total number of trainable parameters in a PyTorch model.

    This function iterates over all parameters in a given PyTorch model and sums up the number of trainable 
    parameters, i.e., those that require gradients.

    :param model: The PyTorch model for which the number of trainable parameters is to be counted.
    :type model: torch.nn.Module
    :return: The total number of trainable parameters in the model.
    :rtype: int
    """
    return sum([p.numel() for p in model.parameters() if p.requires_grad])



def train_lstm_gen(model, optimizer, criterion, dataloader,device):
    """
    Trains an LSTM-based generative model on a given dataset.

    This function performs one epoch of training, iterating over the provided DataLoader.
    It computes the loss, performs backpropagation, and updates the model parameters.

    :param model: The PyTorch model to be trained.
    :type model: torch.nn.Module
    :param optimizer: The optimizer for updating model parameters.
    :type optimizer: torch.optim.Optimizer
    :param criterion: The loss function.
    :type criterion: torch.nn.Module
    :param dataloader: DataLoader for the training data.
    :type dataloader: torch.utils.data.DataLoader
    :param device: Computational device ('cpu' or 'cuda') where tensors should be moved to.
    :type device: str
    :return: Average training loss for the epoch.
    :rtype: float
    """

    model.train()                       
    train_loss= 0  # initialise the loss
    model.to(device)
    for i, (x, y) in enumerate(dataloader):  
        x, y = x.to(device), y.to(device)   
        optimizer.zero_grad()                # reset the gradients
        model.double()
        y_pred = model(x)                   
        loss = criterion(y_pred, y)  
        train_loss += loss                   # addup loss

        loss.backward()                     
        optimizer.step()                     # backpropagate

    return train_loss/len(dataloader)


def val_lstm_gen(model, criterion, dataloader,device):
    """
    Validates an LSTM-based generative model on a given dataset.

    This function performs one epoch of validation, iterating over the provided DataLoader.
    It computes the loss but does not update the model parameters.

    :param model: The PyTorch model to be validated.
    :type model: torch.nn.Module
    :param criterion: The loss function.
    :type criterion: torch.nn.Module
    :param dataloader: DataLoader for the validation data.
    :type dataloader: torch.utils.data.DataLoader
    :param device: Computational device ('cpu' or 'cuda') where tensors should be moved to.
    :type device: str
    :return: Average validation loss for the epoch.
    :rtype: float
    """

    model.eval()                       # no gradient reauired
    val_loss = 0  
    model.to(device)
    for i, (x, y) in enumerate(dataloader):  # loop over dataset

        x, y = x.to(device), y.to(device)    
        model.double()
        y_pred = model(x)                    
        loss = criterion(y_pred, y)  # compute the loss
        val_loss += loss


    return val_loss/len(dataloader)



def calculate_metrics(y_true, y_pred):
    """
    Calculate various statistical metrics between two arrays, including MAE and MAPE.

    Parameters:
    - y_true : array-like, true target values
    - y_pred : array-like, predicted target values

    Returns:
    - metrics : Dictionary containing Bias, RMSE, Scatter Index, Correlation Coefficient, Coefficient of Efficiency, Index of Agreement, MAE, and MAPE
    """
    # Ensure numpy arrays for calculation
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    # Check for the same length
    if len(y_true) != len(y_pred):
        return "The lengths of the true and predicted arrays must be the same."

    # Bias
    bias = np.mean(y_pred - y_true)

    # Root Mean Squared Error (RMSE)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))

    # Scatter Index
    scatter_index = rmse / np.mean(y_true)

    # Correlation Coefficient
    correlation_coefficient = np.corrcoef(y_true, y_pred)[0, 1]

    # Coefficient of Efficiency
    mean_observed = np.mean(y_true)
    coeff_of_efficiency = 1 - (np.sum((y_pred - y_true)**2) / np.sum((y_true - mean_observed)**2))

    # Index of Agreement
    index_of_agreement = 1 - (np.sum((y_pred - y_true)**2) / np.sum((np.abs(y_pred - mean_observed) + np.abs(y_true - mean_observed))**2))

    # Mean Absolute Error (MAE)
    mae = mean_absolute_error(y_true, y_pred)

    # # Mean Absolute Percentage Error (MAPE)
    # mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    metrics = {
        'Bias': bias,
        'RMSE': rmse,
        'Scatter Index': scatter_index,
        'Correlation Coefficient': correlation_coefficient,
        'Coefficient of Efficiency': coeff_of_efficiency,
        'Index of Agreement': index_of_agreement,
        'MAE': mae,
        # 'MAPE': mape
    }

    return metrics